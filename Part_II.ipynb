{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8509872,"sourceType":"datasetVersion","datasetId":5079825}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### MST AIDS 2023-2024 (Département Génie Informatique)\n#### Subject : The main purpose behind this lab is to get familiar with NLP language models using pre-trained GPT-2 model.\n#### Realize by : Chibani Fahd\n#### Topic : Generate recipes\n#### Models : RNN, Bidirectional RNN, GRU and LSTM","metadata":{}},{"cell_type":"markdown","source":"# Part 2 Transformer (Text generation):","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom transformers import GPT2Tokenizer, GPT2LMHeadModel\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\nimport logging\nlogging.getLogger().setLevel(logging.CRITICAL)\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = 'cuda'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-25T12:46:10.934188Z","iopub.execute_input":"2024-05-25T12:46:10.934547Z","iopub.status.idle":"2024-05-25T12:46:17.634200Z","shell.execute_reply.started":"2024-05-25T12:46:10.934515Z","shell.execute_reply":"2024-05-25T12:46:17.632896Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/food-dataset/Food_Dataset.csv\")\ndf","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:46:17.635911Z","iopub.execute_input":"2024-05-25T12:46:17.636457Z","iopub.status.idle":"2024-05-25T12:46:17.720142Z","shell.execute_reply.started":"2024-05-25T12:46:17.636425Z","shell.execute_reply":"2024-05-25T12:46:17.719100Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                  TranslatedIngredients\n0     6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n1     2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n2     1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n3     500 grams Chicken,2 Onion - chopped,1 Tomato -...\n4     1 tablespoon chana dal, 1 tablespoon white ura...\n...                                                 ...\n6292  2 cups Paneer (Homemade Cottage Cheese) - crum...\n6293  1-1/2 cup Risotto - cooked risotto (recipe bel...\n6294  1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...\n6295  150 grams Spring Onion (Bulb & Greens) - chopp...\n6296  1 kg Chicken - medium pieces,1/2 cup Mustard o...\n\n[6297 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>TranslatedIngredients</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>500 grams Chicken,2 Onion - chopped,1 Tomato -...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1 tablespoon chana dal, 1 tablespoon white ura...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6292</th>\n      <td>2 cups Paneer (Homemade Cottage Cheese) - crum...</td>\n    </tr>\n    <tr>\n      <th>6293</th>\n      <td>1-1/2 cup Risotto - cooked risotto (recipe bel...</td>\n    </tr>\n    <tr>\n      <th>6294</th>\n      <td>1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...</td>\n    </tr>\n    <tr>\n      <th>6295</th>\n      <td>150 grams Spring Onion (Bulb &amp; Greens) - chopp...</td>\n    </tr>\n    <tr>\n      <th>6296</th>\n      <td>1 kg Chicken - medium pieces,1/2 cup Mustard o...</td>\n    </tr>\n  </tbody>\n</table>\n<p>6297 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\nmodel = GPT2LMHeadModel.from_pretrained('gpt2-medium')\nmodel = model.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:46:17.721574Z","iopub.execute_input":"2024-05-25T12:46:17.722272Z","iopub.status.idle":"2024-05-25T12:46:26.233462Z","shell.execute_reply.started":"2024-05-25T12:46:17.722235Z","shell.execute_reply":"2024-05-25T12:46:26.232661Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9b6c5a2167849d0859e113ee4760739"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31780984fb214821b13a0e317009884f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da937279fe1c4347a7c953914767add9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef9817e1811a454e968fffd0646f6914"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f57fe757147420a82b77d6c9ee58388"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45ee16aba5e54291a8630ec9ec89201c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8d8e2dc50f84cf084c84d06cc5f93f1"}},"metadata":{}}]},{"cell_type":"code","source":"def choose_from_top(probs, n=5):\n    ind = np.argpartition(probs, -n)[-n:]\n    top_prob = probs[ind]\n    top_prob = top_prob / np.sum(top_prob) # Normalize\n    choice = np.random.choice(n, 1, p = top_prob)\n    token_id = ind[choice][0]\n    return int(token_id)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:46:26.235268Z","iopub.execute_input":"2024-05-25T12:46:26.235558Z","iopub.status.idle":"2024-05-25T12:46:26.241077Z","shell.execute_reply.started":"2024-05-25T12:46:26.235533Z","shell.execute_reply":"2024-05-25T12:46:26.240194Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch.utils.data import Dataset, DataLoader\nimport os\nimport json\nimport csv\n\nclass FoodDataset(Dataset):\n    def __init__(self):\n        super().__init__()\n\n        self.food_list = []\n        self.end_of_text_token = \"<|endoftext|>\"\n\n        with open(\"/kaggle/input/food-dataset/Food_Dataset.csv\") as csv_file:\n            csv_reader = csv.reader(csv_file, delimiter=',')\n\n            x = 0\n            for row in csv_reader:\n                joke_str = f\"recepies:{row[0]}{self.end_of_text_token}\"\n                self.food_list.append(joke_str)\n\n    def __len__(self):\n       return len(self.food_list)\n\n    def __getitem__(self, item):\n        return self.food_list[item]","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:46:26.242132Z","iopub.execute_input":"2024-05-25T12:46:26.242490Z","iopub.status.idle":"2024-05-25T12:46:26.396168Z","shell.execute_reply.started":"2024-05-25T12:46:26.242455Z","shell.execute_reply":"2024-05-25T12:46:26.395271Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"dataset = FoodDataset()\nfood_loader = DataLoader(dataset, batch_size=1, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:46:26.397299Z","iopub.execute_input":"2024-05-25T12:46:26.397619Z","iopub.status.idle":"2024-05-25T12:46:26.433603Z","shell.execute_reply.started":"2024-05-25T12:46:26.397579Z","shell.execute_reply":"2024-05-25T12:46:26.432703Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 2\nEPOCHS = 10\nLEARNING_RATE = 3e-5\nWARMUP_STEPS = 5000\nMAX_SEQ_LEN = 400\nfrom transformers import AdamW, get_linear_schedule_with_warmup\ndevice = 'cpu'\nif torch.cuda.is_available():\n    device = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:46:26.434763Z","iopub.execute_input":"2024-05-25T12:46:26.435085Z","iopub.status.idle":"2024-05-25T12:46:26.448687Z","shell.execute_reply.started":"2024-05-25T12:46:26.435059Z","shell.execute_reply":"2024-05-25T12:46:26.447850Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:46:30.108680Z","iopub.execute_input":"2024-05-25T12:46:30.109327Z","iopub.status.idle":"2024-05-25T12:46:30.115040Z","shell.execute_reply.started":"2024-05-25T12:46:30.109291Z","shell.execute_reply":"2024-05-25T12:46:30.114187Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"model = model.to(device)\nmodel.train()\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps = -1)\nproc_seq_count = 0\nsum_loss = 0.0\nbatch_count = 0\n\ntmp_food_tens = None\nmodels_folder = \"trained_models\"\nif not os.path.exists(models_folder):\n    os.mkdir(models_folder)\n\nfor epoch in range(EPOCHS):\n    \n    print(f\"EPOCH {epoch} started\" + '=' * 30)\n    \n    for idx,food in enumerate(food_loader):\n        \n        #################### \"Fit as many recipes sequences into MAX_SEQ_LEN sequence as possible\" logic start ####\n        food_tens = torch.tensor(tokenizer.encode(food[0])).unsqueeze(0).to(device)\n        #Skip sample from dataset if it is longer than MAX_SEQ_LEN\n        if food_tens.size()[1] > MAX_SEQ_LEN:\n            continue\n        \n        #The first recipes sequence in the sequence\n        if not torch.is_tensor(tmp_food_tens):\n            tmp_food_tens = food_tens\n            continue\n        else:\n            #The next recipes does not fit in so we process the sequence and leave the last recipes \n            #as the start for next sequence \n            if tmp_food_tens.size()[1] + food_tens.size()[1] > MAX_SEQ_LEN:\n                work_food_tens = tmp_food_tens\n                tmp_food_tens = food_tens\n            else:\n                #Add the recipes to sequence, continue and try to add more\n                tmp_food_tens = torch.cat([tmp_food_tens, food_tens[:,1:]], dim=1)\n                continue\n        ################## Sequence ready, process it trough the model ##################\n            \n        outputs = model(work_food_tens, labels=work_food_tens)\n        loss, logits = outputs[:2]                        \n        loss.backward()\n        sum_loss = sum_loss + loss.detach().data\n                       \n        proc_seq_count = proc_seq_count + 1\n        if proc_seq_count == BATCH_SIZE:\n            proc_seq_count = 0    \n            batch_count += 1\n            optimizer.step()\n            scheduler.step() \n            optimizer.zero_grad()\n            model.zero_grad()\n\n        if batch_count == 100:\n            print(f\"sum loss {sum_loss}\")\n            batch_count = 0\n            sum_loss = 0.0\n    \n    # Store the model after each epoch to compare the performance of them\ntorch.save(model.state_dict(), os.path.join(models_folder, f\"gpt2_medium_food_{epoch}.pt\"))","metadata":{"execution":{"iopub.status.busy":"2024-05-25T12:46:55.267510Z","iopub.execute_input":"2024-05-25T12:46:55.267967Z","iopub.status.idle":"2024-05-25T13:49:36.445663Z","shell.execute_reply.started":"2024-05-25T12:46:55.267928Z","shell.execute_reply":"2024-05-25T13:49:36.444838Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"EPOCH 0 started==============================\nsum loss 602.9174194335938\nsum loss 531.919677734375\nsum loss 475.10040283203125\nsum loss 426.5258483886719\nsum loss 392.7735900878906\nsum loss 363.0346374511719\nsum loss 333.07049560546875\nsum loss 325.109619140625\nsum loss 306.9200439453125\nsum loss 293.888671875\nEPOCH 1 started==============================\nsum loss 277.667724609375\nsum loss 271.6908264160156\nsum loss 266.42974853515625\nsum loss 263.4397277832031\nsum loss 257.0422058105469\nsum loss 254.81268310546875\nsum loss 255.25730895996094\nsum loss 248.59228515625\nsum loss 243.5207977294922\nsum loss 242.1642303466797\nEPOCH 2 started==============================\nsum loss 235.9222869873047\nsum loss 233.20223999023438\nsum loss 232.08453369140625\nsum loss 230.86383056640625\nsum loss 229.44541931152344\nsum loss 224.79991149902344\nsum loss 223.1371612548828\nsum loss 223.06190490722656\nsum loss 221.6030731201172\nsum loss 222.78575134277344\nEPOCH 3 started==============================\nsum loss 217.31240844726562\nsum loss 213.71771240234375\nsum loss 212.77481079101562\nsum loss 209.7014617919922\nsum loss 214.14166259765625\nsum loss 217.23526000976562\nsum loss 211.1446533203125\nsum loss 211.01895141601562\nsum loss 208.32696533203125\nsum loss 210.52902221679688\nEPOCH 4 started==============================\nsum loss 205.19540405273438\nsum loss 202.75645446777344\nsum loss 199.966796875\nsum loss 205.24893188476562\nsum loss 201.14817810058594\nsum loss 200.87722778320312\nsum loss 203.49960327148438\nsum loss 201.28421020507812\nsum loss 199.71224975585938\nsum loss 204.80972290039062\nEPOCH 5 started==============================\nsum loss 196.6446533203125\nsum loss 193.89170837402344\nsum loss 192.91519165039062\nsum loss 191.45755004882812\nsum loss 192.81065368652344\nsum loss 197.25601196289062\nsum loss 189.45103454589844\nsum loss 195.4762725830078\nsum loss 194.0223846435547\nsum loss 195.0557403564453\nEPOCH 6 started==============================\nsum loss 196.6282196044922\nsum loss 193.1215362548828\nsum loss 192.135009765625\nsum loss 192.1498260498047\nsum loss 197.27532958984375\nsum loss 195.12037658691406\nsum loss 193.20326232910156\nsum loss 196.6825714111328\nsum loss 192.8882598876953\nsum loss 193.5799560546875\nsum loss 195.0081787109375\nEPOCH 7 started==============================\nsum loss 194.46080017089844\nsum loss 196.6654052734375\nsum loss 195.78819274902344\nsum loss 196.2468719482422\nsum loss 196.0334930419922\nsum loss 187.97433471679688\nsum loss 191.09136962890625\nsum loss 193.67611694335938\nsum loss 193.51304626464844\nsum loss 193.51527404785156\nEPOCH 8 started==============================\nsum loss 192.9392852783203\nsum loss 195.66275024414062\nsum loss 194.54563903808594\nsum loss 195.54971313476562\nsum loss 194.5702667236328\nsum loss 196.51808166503906\nsum loss 192.77276611328125\nsum loss 193.5414276123047\nsum loss 194.78184509277344\nsum loss 191.40106201171875\nEPOCH 9 started==============================\nsum loss 190.19236755371094\nsum loss 193.22369384765625\nsum loss 192.7480010986328\nsum loss 191.38499450683594\nsum loss 192.3828125\nsum loss 194.9867706298828\nsum loss 195.2096405029297\nsum loss 195.941650390625\nsum loss 191.61712646484375\nsum loss 195.60459899902344\n","output_type":"stream"}]},{"cell_type":"code","source":"MODEL_EPOCH = 9\n\nmodels_folder = \"trained_models\"\n\nmodel_path = os.path.join(models_folder, f\"gpt2_medium_joker_{MODEL_EPOCH}.pt\")\nmodel.load_state_dict(torch.load(model_path))\n\nfood_output_file_path = f'generated_{MODEL_EPOCH}.food'\n\nmodel.eval()\nif os.path.exists(food_output_file_path):\n    os.remove(food_output_file_path)\n    \nfood_num = 0\nwith torch.no_grad():\n   \n        for food_idx in range(5):\n        \n            food_finished = False\n\n            cur_ids = torch.tensor(tokenizer.encode(\"Recipes :\")).unsqueeze(0).to(device)\n\n            for i in range(100):\n                outputs = model(cur_ids, labels=cur_ids)\n                loss, logits = outputs[:2]\n                softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(from only one in this case) batch and the last predicted embedding\n                if i < 3:\n                    n = 20\n                else:\n                    n = 3\n                next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), n=n) #Randomly(from the topN probability distribution) select the next word\n                cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) # Add the last word to the running sequence\n\n                if next_token_id in tokenizer.encode('<|endoftext|>'):\n                    food_finished = True\n                    break\n\n            \n            if food_finished:\n                \n                food_num = food_num + 1\n                \n                output_list = list(cur_ids.squeeze().to('cpu').numpy())\n                output_text = tokenizer.decode(output_list)\n\n                with open(jokes_output_file_path, 'a') as f:\n                    f.write(f\"{output_text} \\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-05-25T14:13:41.485370Z","iopub.execute_input":"2024-05-25T14:13:41.485730Z","iopub.status.idle":"2024-05-25T14:13:52.254418Z","shell.execute_reply.started":"2024-05-25T14:13:41.485701Z","shell.execute_reply":"2024-05-25T14:13:52.253355Z"},"trusted":true},"execution_count":17,"outputs":[]}]}