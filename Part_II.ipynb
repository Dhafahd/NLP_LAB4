{"cells":[{"cell_type":"markdown","metadata":{},"source":["#### MST AIDS 2023-2024 (Département Génie Informatique)\n","#### Subject : The main purpose behind this lab is to get familiar with NLP language models using pre-trained GPT-2 model.\n","#### Realize by : Chibani Fahd\n","#### Topic : Generate recipes\n","#### Models : RNN, Bidirectional RNN, GRU and LSTM"]},{"cell_type":"markdown","metadata":{},"source":["# Part 2 Transformer (Text generation):"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-25T12:46:10.934547Z","iopub.status.busy":"2024-05-25T12:46:10.934188Z","iopub.status.idle":"2024-05-25T12:46:17.634200Z","shell.execute_reply":"2024-05-25T12:46:17.632896Z","shell.execute_reply.started":"2024-05-25T12:46:10.934515Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import torch\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","import logging\n","logging.getLogger().setLevel(logging.CRITICAL)\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","device = 'cpu'\n","if torch.cuda.is_available():\n","    device = 'cuda'"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T12:46:17.636457Z","iopub.status.busy":"2024-05-25T12:46:17.635911Z","iopub.status.idle":"2024-05-25T12:46:17.720142Z","shell.execute_reply":"2024-05-25T12:46:17.719100Z","shell.execute_reply.started":"2024-05-25T12:46:17.636425Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TranslatedIngredients</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>500 grams Chicken,2 Onion - chopped,1 Tomato -...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1 tablespoon chana dal, 1 tablespoon white ura...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6292</th>\n","      <td>2 cups Paneer (Homemade Cottage Cheese) - crum...</td>\n","    </tr>\n","    <tr>\n","      <th>6293</th>\n","      <td>1-1/2 cup Risotto - cooked risotto (recipe bel...</td>\n","    </tr>\n","    <tr>\n","      <th>6294</th>\n","      <td>1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...</td>\n","    </tr>\n","    <tr>\n","      <th>6295</th>\n","      <td>150 grams Spring Onion (Bulb &amp; Greens) - chopp...</td>\n","    </tr>\n","    <tr>\n","      <th>6296</th>\n","      <td>1 kg Chicken - medium pieces,1/2 cup Mustard o...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6297 rows × 1 columns</p>\n","</div>"],"text/plain":["                                  TranslatedIngredients\n","0     6 Karela (Bitter Gourd/ Pavakkai) - deseeded,S...\n","1     2-1 / 2 cups rice - cooked, 3 tomatoes, 3 teas...\n","2     1-1/2 cups Rice Vermicelli Noodles (Thin),1 On...\n","3     500 grams Chicken,2 Onion - chopped,1 Tomato -...\n","4     1 tablespoon chana dal, 1 tablespoon white ura...\n","...                                                 ...\n","6292  2 cups Paneer (Homemade Cottage Cheese) - crum...\n","6293  1-1/2 cup Risotto - cooked risotto (recipe bel...\n","6294  1 cup Quinoa,3/4 cup Sugar,1 teaspoon Cardamom...\n","6295  150 grams Spring Onion (Bulb & Greens) - chopp...\n","6296  1 kg Chicken - medium pieces,1/2 cup Mustard o...\n","\n","[6297 rows x 1 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["df=pd.read_csv(\"/kaggle/input/food-dataset/Food_Dataset.csv\")\n","df"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T12:46:17.722272Z","iopub.status.busy":"2024-05-25T12:46:17.721574Z","iopub.status.idle":"2024-05-25T12:46:26.233462Z","shell.execute_reply":"2024-05-25T12:46:26.232661Z","shell.execute_reply.started":"2024-05-25T12:46:17.722235Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f9b6c5a2167849d0859e113ee4760739","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"31780984fb214821b13a0e317009884f","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"da937279fe1c4347a7c953914767add9","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef9817e1811a454e968fffd0646f6914","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f57fe757147420a82b77d6c9ee58388","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"45ee16aba5e54291a8630ec9ec89201c","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8d8e2dc50f84cf084c84d06cc5f93f1","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n","model = GPT2LMHeadModel.from_pretrained('gpt2-medium')\n","model = model.to(device)\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T12:46:26.235558Z","iopub.status.busy":"2024-05-25T12:46:26.235268Z","iopub.status.idle":"2024-05-25T12:46:26.241077Z","shell.execute_reply":"2024-05-25T12:46:26.240194Z","shell.execute_reply.started":"2024-05-25T12:46:26.235533Z"},"trusted":true},"outputs":[],"source":["def choose_from_top(probs, n=5):\n","    ind = np.argpartition(probs, -n)[-n:]\n","    top_prob = probs[ind]\n","    top_prob = top_prob / np.sum(top_prob) # Normalize\n","    choice = np.random.choice(n, 1, p = top_prob)\n","    token_id = ind[choice][0]\n","    return int(token_id)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T12:46:26.242490Z","iopub.status.busy":"2024-05-25T12:46:26.242132Z","iopub.status.idle":"2024-05-25T12:46:26.396168Z","shell.execute_reply":"2024-05-25T12:46:26.395271Z","shell.execute_reply.started":"2024-05-25T12:46:26.242455Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","import json\n","import csv\n","\n","class FoodDataset(Dataset):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.food_list = []\n","        self.end_of_text_token = \"<|endoftext|>\"\n","\n","        with open(\"/kaggle/input/food-dataset/Food_Dataset.csv\") as csv_file:\n","            csv_reader = csv.reader(csv_file, delimiter=',')\n","\n","            x = 0\n","            for row in csv_reader:\n","                joke_str = f\"recepies:{row[0]}{self.end_of_text_token}\"\n","                self.food_list.append(joke_str)\n","\n","    def __len__(self):\n","       return len(self.food_list)\n","\n","    def __getitem__(self, item):\n","        return self.food_list[item]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T12:46:26.397619Z","iopub.status.busy":"2024-05-25T12:46:26.397299Z","iopub.status.idle":"2024-05-25T12:46:26.433603Z","shell.execute_reply":"2024-05-25T12:46:26.432703Z","shell.execute_reply.started":"2024-05-25T12:46:26.397579Z"},"trusted":true},"outputs":[],"source":["dataset = FoodDataset()\n","food_loader = DataLoader(dataset, batch_size=1, shuffle=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T12:46:26.435085Z","iopub.status.busy":"2024-05-25T12:46:26.434763Z","iopub.status.idle":"2024-05-25T12:46:26.448687Z","shell.execute_reply":"2024-05-25T12:46:26.447850Z","shell.execute_reply.started":"2024-05-25T12:46:26.435059Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 2\n","EPOCHS = 10\n","LEARNING_RATE = 3e-5\n","WARMUP_STEPS = 5000\n","MAX_SEQ_LEN = 400\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","device = 'cpu'\n","if torch.cuda.is_available():\n","    device = 'cuda'"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T12:46:30.109327Z","iopub.status.busy":"2024-05-25T12:46:30.108680Z","iopub.status.idle":"2024-05-25T12:46:30.115040Z","shell.execute_reply":"2024-05-25T12:46:30.114187Z","shell.execute_reply.started":"2024-05-25T12:46:30.109291Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'cuda'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T12:46:55.267967Z","iopub.status.busy":"2024-05-25T12:46:55.267510Z","iopub.status.idle":"2024-05-25T13:49:36.445663Z","shell.execute_reply":"2024-05-25T13:49:36.444838Z","shell.execute_reply.started":"2024-05-25T12:46:55.267928Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["EPOCH 0 started==============================\n","sum loss 602.9174194335938\n","sum loss 531.919677734375\n","sum loss 475.10040283203125\n","sum loss 426.5258483886719\n","sum loss 392.7735900878906\n","sum loss 363.0346374511719\n","sum loss 333.07049560546875\n","sum loss 325.109619140625\n","sum loss 306.9200439453125\n","sum loss 293.888671875\n","EPOCH 1 started==============================\n","sum loss 277.667724609375\n","sum loss 271.6908264160156\n","sum loss 266.42974853515625\n","sum loss 263.4397277832031\n","sum loss 257.0422058105469\n","sum loss 254.81268310546875\n","sum loss 255.25730895996094\n","sum loss 248.59228515625\n","sum loss 243.5207977294922\n","sum loss 242.1642303466797\n","EPOCH 2 started==============================\n","sum loss 235.9222869873047\n","sum loss 233.20223999023438\n","sum loss 232.08453369140625\n","sum loss 230.86383056640625\n","sum loss 229.44541931152344\n","sum loss 224.79991149902344\n","sum loss 223.1371612548828\n","sum loss 223.06190490722656\n","sum loss 221.6030731201172\n","sum loss 222.78575134277344\n","EPOCH 3 started==============================\n","sum loss 217.31240844726562\n","sum loss 213.71771240234375\n","sum loss 212.77481079101562\n","sum loss 209.7014617919922\n","sum loss 214.14166259765625\n","sum loss 217.23526000976562\n","sum loss 211.1446533203125\n","sum loss 211.01895141601562\n","sum loss 208.32696533203125\n","sum loss 210.52902221679688\n","EPOCH 4 started==============================\n","sum loss 205.19540405273438\n","sum loss 202.75645446777344\n","sum loss 199.966796875\n","sum loss 205.24893188476562\n","sum loss 201.14817810058594\n","sum loss 200.87722778320312\n","sum loss 203.49960327148438\n","sum loss 201.28421020507812\n","sum loss 199.71224975585938\n","sum loss 204.80972290039062\n","EPOCH 5 started==============================\n","sum loss 196.6446533203125\n","sum loss 193.89170837402344\n","sum loss 192.91519165039062\n","sum loss 191.45755004882812\n","sum loss 192.81065368652344\n","sum loss 197.25601196289062\n","sum loss 189.45103454589844\n","sum loss 195.4762725830078\n","sum loss 194.0223846435547\n","sum loss 195.0557403564453\n","EPOCH 6 started==============================\n","sum loss 196.6282196044922\n","sum loss 193.1215362548828\n","sum loss 192.135009765625\n","sum loss 192.1498260498047\n","sum loss 197.27532958984375\n","sum loss 195.12037658691406\n","sum loss 193.20326232910156\n","sum loss 196.6825714111328\n","sum loss 192.8882598876953\n","sum loss 193.5799560546875\n","sum loss 195.0081787109375\n","EPOCH 7 started==============================\n","sum loss 194.46080017089844\n","sum loss 196.6654052734375\n","sum loss 195.78819274902344\n","sum loss 196.2468719482422\n","sum loss 196.0334930419922\n","sum loss 187.97433471679688\n","sum loss 191.09136962890625\n","sum loss 193.67611694335938\n","sum loss 193.51304626464844\n","sum loss 193.51527404785156\n","EPOCH 8 started==============================\n","sum loss 192.9392852783203\n","sum loss 195.66275024414062\n","sum loss 194.54563903808594\n","sum loss 195.54971313476562\n","sum loss 194.5702667236328\n","sum loss 196.51808166503906\n","sum loss 192.77276611328125\n","sum loss 193.5414276123047\n","sum loss 194.78184509277344\n","sum loss 191.40106201171875\n","EPOCH 9 started==============================\n","sum loss 190.19236755371094\n","sum loss 193.22369384765625\n","sum loss 192.7480010986328\n","sum loss 191.38499450683594\n","sum loss 192.3828125\n","sum loss 194.9867706298828\n","sum loss 195.2096405029297\n","sum loss 195.941650390625\n","sum loss 191.61712646484375\n","sum loss 195.60459899902344\n"]}],"source":["model = model.to(device)\n","model.train()\n","optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps = -1)\n","proc_seq_count = 0\n","sum_loss = 0.0\n","batch_count = 0\n","\n","tmp_food_tens = None\n","models_folder = \"trained_models\"\n","if not os.path.exists(models_folder):\n","    os.mkdir(models_folder)\n","\n","for epoch in range(EPOCHS):\n","    \n","    print(f\"EPOCH {epoch} started\" + '=' * 30)\n","    \n","    for idx,food in enumerate(food_loader):\n","        \n","        #################### \"Fit as many recipes sequences into MAX_SEQ_LEN sequence as possible\" logic start ####\n","        food_tens = torch.tensor(tokenizer.encode(food[0])).unsqueeze(0).to(device)\n","        #Skip sample from dataset if it is longer than MAX_SEQ_LEN\n","        if food_tens.size()[1] > MAX_SEQ_LEN:\n","            continue\n","        \n","        #The first recipes sequence in the sequence\n","        if not torch.is_tensor(tmp_food_tens):\n","            tmp_food_tens = food_tens\n","            continue\n","        else:\n","            #The next recipes does not fit in so we process the sequence and leave the last recipes \n","            #as the start for next sequence \n","            if tmp_food_tens.size()[1] + food_tens.size()[1] > MAX_SEQ_LEN:\n","                work_food_tens = tmp_food_tens\n","                tmp_food_tens = food_tens\n","            else:\n","                #Add the recipes to sequence, continue and try to add more\n","                tmp_food_tens = torch.cat([tmp_food_tens, food_tens[:,1:]], dim=1)\n","                continue\n","        ################## Sequence ready, process it trough the model ##################\n","            \n","        outputs = model(work_food_tens, labels=work_food_tens)\n","        loss, logits = outputs[:2]                        \n","        loss.backward()\n","        sum_loss = sum_loss + loss.detach().data\n","                       \n","        proc_seq_count = proc_seq_count + 1\n","        if proc_seq_count == BATCH_SIZE:\n","            proc_seq_count = 0    \n","            batch_count += 1\n","            optimizer.step()\n","            scheduler.step() \n","            optimizer.zero_grad()\n","            model.zero_grad()\n","\n","        if batch_count == 100:\n","            print(f\"sum loss {sum_loss}\")\n","            batch_count = 0\n","            sum_loss = 0.0\n","    \n","    # Store the model after each epoch to compare the performance of them\n","torch.save(model.state_dict(), os.path.join(models_folder, f\"gpt2_medium_food_{epoch}.pt\"))"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-25T14:13:41.485730Z","iopub.status.busy":"2024-05-25T14:13:41.485370Z","iopub.status.idle":"2024-05-25T14:13:52.254418Z","shell.execute_reply":"2024-05-25T14:13:52.253355Z","shell.execute_reply.started":"2024-05-25T14:13:41.485701Z"},"trusted":true},"outputs":[],"source":["MODEL_EPOCH = 9\n","\n","models_folder = \"trained_models\"\n","\n","model_path = os.path.join(models_folder, f\"gpt2_medium_joker_{MODEL_EPOCH}.pt\")\n","model.load_state_dict(torch.load(model_path))\n","\n","food_output_file_path = f'generated_{MODEL_EPOCH}.food'\n","\n","model.eval()\n","if os.path.exists(food_output_file_path):\n","    os.remove(food_output_file_path)\n","    \n","food_num = 0\n","with torch.no_grad():\n","   \n","        for food_idx in range(4):\n","        \n","            food_finished = False\n","\n","            cur_ids = torch.tensor(tokenizer.encode(\"Recipes :\")).unsqueeze(0).to(device)\n","\n","            for i in range(100):\n","                outputs = model(cur_ids, labels=cur_ids)\n","                loss, logits = outputs[:2]\n","                softmax_logits = torch.softmax(logits[0,-1], dim=0) #Take the first(from only one in this case) batch and the last predicted embedding\n","                if i < 3:\n","                    n = 20\n","                else:\n","                    n = 3\n","                next_token_id = choose_from_top(softmax_logits.to('cpu').numpy(), n=n) #Randomly(from the topN probability distribution) select the next word\n","                cur_ids = torch.cat([cur_ids, torch.ones((1,1)).long().to(device) * next_token_id], dim = 1) # Add the last word to the running sequence\n","\n","                if next_token_id in tokenizer.encode('<|endoftext|>'):\n","                    food_finished = True\n","                    break\n","\n","            \n","            if food_finished:\n","                \n","                food_num = food_num + 1\n","                \n","                output_list = list(cur_ids.squeeze().to('cpu').numpy())\n","                output_text = tokenizer.decode(output_list)\n","\n","                with open(food_tens_output_file_path, 'a') as f:\n","                    f.write(f\"{output_text} \\n\\n\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5079825,"sourceId":8509872,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
